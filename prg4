import numpy as np
from sklearn.datasets import load_iris, make_moons
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score
from collections import Counter
# Custom k-NN function
def knn(X_train, y_train, X_test, k=3, weighted=False):
predictions = []
for x in X_test:
dists = np.linalg.norm(X_train - x, axis=1)
idx = np.argsort(dists)[:k]
if weighted:
weights = 1 / (dists[idx]**2 + 1e-5) # Avoid division by 0
class_scores = {}
for i, w in zip(idx, weights):
class_scores[y_train[i]] = class_scores.get(y_train[i], 0) + w
pred = max(class_scores, key=class_scores.get)
else:
pred = Counter(y_train[idx]).most_common(1)[0][0]
predictions.append(pred)
return np.array(predictions)
# Evaluation function
def evaluate(X_train, X_test, y_train, y_test, dataset_name="Dataset"):
print(f"\n Results for {dataset_name}")
for weighted in [False, True]:
print("\n" + ("Weighted" if weighted else "Regular") + " k-NN:")
for k in [1, 3, 5]:
y_pred = knn(X_train, y_train, X_test, k, weighted)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average='macro')
print(f" k={k}: Accuracy = {acc:.3f}, F1-score = {f1:.3f}")
# Load and evaluate Iris dataset
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
iris.data, iris.target, test_size=0.3, random_state=42, stratify=iris.target
)
evaluate(X_train, X_test, y_train, y_test, "Iris Dataset")
# Load and evaluate synthetic dataset (moons)
X_syn, y_syn = make_moons(n_samples=300, noise=0.3, random_state=42)
X_syn_train, X_syn_test, y_syn_train, y_syn_test = train_test_split(
X_syn, y_syn, test_size=0.3, random_state=42
)
evaluate(X_syn_train, X_syn_test, y_syn_train, y_syn_test, "Synthetic Moons Dataset")
