# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# Load Boston Housing dataset
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
df = pd.read_csv(url)
print(df)
# Select feature and target
X = df[['rm']] y = df['medv'] # Independent variable (number of rooms)
# Dependent variable (house price)
# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,
random_state=42)
# Train Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)
# Predict house prices
y_pred = model.predict(X_test)
# Visualization
plt.figure(figsize=(10, 6))
# Scatter plot of actual values (flattened arrays)
sns.scatterplot(x=X_test["rm"], y=y_test.values.flatten(), color='blue', label='Actual
Prices')
# Regression line over the entire range of X values
x_range = np.linspace(X['rm'].min(), X['rm'].max(), 100).reshape(-1, 1)
y_range = lin_reg.predict(x_range)
plt.plot(x_range, y_range, color='red', label='Regression Line')
# Labels and Title
plt.xlabel("Average Number of Rooms (RM)")
plt.ylabel("Median House Price ($1000s)")
plt.title("Linear Regression - Boston Housing Dataset")
plt.legend()
plt.grid(True)
plt.show()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
# Load Auto MPG Dataset from CSV
url = "https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv"
df = pd.read_csv(url)
print(df)
# Drop missing values
df.dropna(inplace=True)
# Select "horsepower" as feature and "mpg" as target
X = df[['horsepower']]
y = df['mpg']
print(X)
print(y)
# Standardize feature
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print(X_scaled)
# Train Polynomial Regression Model (degree = 3)
poly_model = make_pipeline(PolynomialFeatures(degree=3), LinearRegression())
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2,
random_state=42)
poly_model.fit(X_train, y_train)
y_poly_pred = poly_model.predict(X_test)
# Sort values for smooth curve
sorted_indices = np.argsort(X_test[:, 0])
X_test_sorted = X_test[sorted_indices]
y_poly_pred_sorted = y_poly_pred[sorted_indices]
# Plot Results
plt.figure(figsize=(8, 5))
sns.scatterplot(x=X_test[:, 0], y=y_test, label="Actual MPG", color="blue")
sns.lineplot(x=X_test_sorted[:, 0], y=y_poly_pred_sorted, label="Polynomial Fit",
color="red")
plt.xlabel("Horsepower (Standardized)")
plt.ylabel("Miles Per Gallon (MPG)")
plt.title("Polynomial Regression - Auto MPG")
plt.legend()
plt.show()
